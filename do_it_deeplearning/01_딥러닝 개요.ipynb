{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델이 데이터를 암기하는 현상: 과적합\n",
    "과적합은 모델이 과도하게 학습되어 '데이터를 암기'한 상태로, 모델 분산이 커졌기 때문에 관측 데이터는 정확히 예측하지만 새로운 데이터는 정확히 예측하지 못한다. 과적합의 주요 원인은 학습 데이터보다 모델의 파라미터 수가 많기 때문이다.  \n",
    "그래서 모델 파라미터가 많은 인공신경망은 다른 모델보다 과적합되기 쉽다.  \n",
    "\n",
    "* 학습이 중단되는 현상: 그래디언트 소실\n",
    "깊은 신경망을 학습할 때 역전파 과정에서 미분값이 사라지면서 학습이 중단되는 현상을 말한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1acd79579433d099a774017ba86d1314ddef5b0bdc137c47399c89169a3fec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
