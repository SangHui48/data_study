{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gYZLXJSZPtmI",
        "outputId": "6c166284-4cc0-423e-dd81-4efe81698c7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "print(x.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1MMmXIUQphv",
        "outputId": "a5cc8d75-5720-4cab-b129-8517053c975f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98TuICHEQ28E",
        "outputId": "598cff23-0322-4820-94c9-872b2f5d2887"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()"
      ],
      "metadata": {
        "id": "GHhotdIXRAVN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(z)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_hV8rxcRL1L",
        "outputId": "62fe6a28-75f9-4033-e56a-4e7a1b7c0d6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "y.retain_grad()\n",
        "out.backward(retain_graph=True)\n",
        "\n",
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)\n",
        "print(z.is_leaf)\n",
        "\n",
        "out.backward()\n",
        "print(x.grad)\n",
        "print(y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az0U25dwROq0",
        "outputId": "0f48770d-0cf0-4b2e-b810-2dcbe04d10be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n",
            "None\n",
            "False\n",
            "tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "tensor([[9., 9.],\n",
            "        [9., 9.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-1f70e90c9618>:13: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(z.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "1-DecA8tU_Lq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.layer0 = nn.Linear(4, 128)\n",
        "    self.layer1 = nn.Linear(128, 64)\n",
        "    self.layer2 = nn.Linear(64, 32)\n",
        "    self.layer3 = nn.Linear(32, 16)\n",
        "    self.layer4 = nn.Linear(16, 3)\n",
        "\n",
        "    self.bn0 = nn.BatchNorm1d(128)\n",
        "    self.bn1 = nn.BatchNorm1d(64)\n",
        "    self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "    self.act = nn.ReLU()\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.act(self.bn0(self.layer0(x)))\n",
        "    x = self.act(self.bn1(self.layer1(x)))\n",
        "    x = self.act(self.bn2(self.layer2(x)))\n",
        "    x = self.act(self.layer3(x))\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "bELoqaGBdp3B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "ex_X, ex_y = torch.randn([4, 4]), torch.tensor([1, 0, 2, 0])"
      ],
      "metadata": {
        "id": "W_X0l-cwelUE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "output = net(ex_X)\n",
        "loss = criterion(output, ex_y)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVAYQtGKfGxR",
        "outputId": "389950b9-64be-4936-dd18-db12f6c8038a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0715, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8WRWOJ7fM1N",
        "outputId": "34e8d761-612d-45da-b98e-31ce7b64afe4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0715147256851196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.zero_grad()"
      ],
      "metadata": {
        "id": "oYiT_EMCfd2a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.layer4.bias.grad)\n",
        "print(net.layer4.bias.is_leaf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lcS194rgFZU",
        "outputId": "5a66cfae-aeef-42c7-ea3b-4837c01167f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "3vCRGP3NgMeM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.layer4.bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2MUXMZ9gQB6",
        "outputId": "d8cff999-5119-4a1a-a70a-c6f485b31a50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1226,  0.0630,  0.0595])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(net.parameters())"
      ],
      "metadata": {
        "id": "BfdbTZq4gTyH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKCfGXsEgzaA",
        "outputId": "47aa01ea-5365-41fd-f6bb-c5d65a68e3c3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params[0].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYVemMuyg0Z8",
        "outputId": "6589a620-1a14-4de6-844a-39c6342bd33a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "output = net(ex_X)\n",
        "loss = criterion(output, ex_y)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "4BaDVU30hF_H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_iris()\n",
        "\n",
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu0C6pclhdUa",
        "outputId": "69dfd149-d88e-4813-b3a6-a6fac134d37b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils._bunch.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.data\n",
        "label = dataset.target\n",
        "\n",
        "print(dataset.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQNwLAmLhwIM",
        "outputId": "6ed9a6a7-4410-4b4e-b720-a7488c1cea28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape of data: {data.shape}')\n",
        "print(f'shape of label: {label.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "letsuWqhh7R4",
        "outputId": "b9d17df1-747c-4470-ba56-ba0ea57d9e15"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data: (150, 4)\n",
            "shape of label: (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.25, stratify=label)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFNypcxOiUnl",
        "outputId": "5fe092eb-010c-4c8e-d7e8-5ccf11e5fab2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112\n",
            "38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 생성\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "train_set = TensorDataset(X_train, y_train)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "2PBjl6MZiv-9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()"
      ],
      "metadata": {
        "id": "3kT8spDLkDCD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJoJD2YmkOuk",
        "outputId": "e055d9d8-380e-45d3-ddd3-c29ad6154bb5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layer0): Linear(in_features=4, out_features=128, bias=True)\n",
            "  (layer1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (layer2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (layer3): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (layer4): Linear(in_features=16, out_features=3, bias=True)\n",
            "  (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (act): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "lsgice9VkPSz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K771cn-AkjG9",
        "outputId": "e9152a84-a53b-4409-f6ae-c677e35cb11b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhu-JttPkkOo",
        "outputId": "4155d992-acac-418f-e942-13c1eed052d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layer0): Linear(in_features=4, out_features=128, bias=True)\n",
              "  (layer1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (layer2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (layer3): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (layer4): Linear(in_features=16, out_features=3, bias=True)\n",
              "  (bn0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 200"
      ],
      "metadata": {
        "id": "aB21gVd1kmWr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = list()\n",
        "accuracies = list()\n",
        "\n",
        "for epoch in range(200):\n",
        "  epoch_loss, epoch_accuracy = 0, 0\n",
        "  for X, y in train_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = net(X)\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "    accuracy = (predicted == y).sum().item()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_accuracy += accuracy\n",
        "  \n",
        "  epoch_loss /= len(train_loader)\n",
        "  epoch_accuracy /= len(X_train)\n",
        "  print(\"epoch: {}, \\tloss: {}, \\taccuracy: {}\".format(str(epoch+1).zfill(3), round(epoch_loss, 4), round(epoch_accuracy,4)))\n",
        "\n",
        "  losses.append(epoch_loss)\n",
        "  accuracies.append(epoch_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mskmAmElSc-",
        "outputId": "2ebf1b82-56a6-4db3-f5bf-8f3c1f8d9fe7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 001, \tloss: 1.0723, \taccuracy: 0.3839\n",
            "epoch: 002, \tloss: 1.0662, \taccuracy: 0.375\n",
            "epoch: 003, \tloss: 1.0545, \taccuracy: 0.4018\n",
            "epoch: 004, \tloss: 1.0355, \taccuracy: 0.4464\n",
            "epoch: 005, \tloss: 1.0331, \taccuracy: 0.5089\n",
            "epoch: 006, \tloss: 1.0203, \taccuracy: 0.5357\n",
            "epoch: 007, \tloss: 1.0288, \taccuracy: 0.5357\n",
            "epoch: 008, \tloss: 1.0107, \taccuracy: 0.5982\n",
            "epoch: 009, \tloss: 1.0016, \taccuracy: 0.6161\n",
            "epoch: 010, \tloss: 1.0152, \taccuracy: 0.5268\n",
            "epoch: 011, \tloss: 1.0127, \taccuracy: 0.5089\n",
            "epoch: 012, \tloss: 0.9803, \taccuracy: 0.6607\n",
            "epoch: 013, \tloss: 0.9802, \taccuracy: 0.6518\n",
            "epoch: 014, \tloss: 0.9726, \taccuracy: 0.6964\n",
            "epoch: 015, \tloss: 0.9725, \taccuracy: 0.6429\n",
            "epoch: 016, \tloss: 0.9546, \taccuracy: 0.6696\n",
            "epoch: 017, \tloss: 0.9559, \taccuracy: 0.6696\n",
            "epoch: 018, \tloss: 0.9532, \taccuracy: 0.6607\n",
            "epoch: 019, \tloss: 0.9347, \taccuracy: 0.6518\n",
            "epoch: 020, \tloss: 0.9322, \taccuracy: 0.75\n",
            "epoch: 021, \tloss: 0.9239, \taccuracy: 0.7232\n",
            "epoch: 022, \tloss: 0.9243, \taccuracy: 0.7232\n",
            "epoch: 023, \tloss: 0.9123, \taccuracy: 0.7321\n",
            "epoch: 024, \tloss: 0.905, \taccuracy: 0.7232\n",
            "epoch: 025, \tloss: 0.8933, \taccuracy: 0.7321\n",
            "epoch: 026, \tloss: 0.9083, \taccuracy: 0.6964\n",
            "epoch: 027, \tloss: 0.8795, \taccuracy: 0.7768\n",
            "epoch: 028, \tloss: 0.8625, \taccuracy: 0.7589\n",
            "epoch: 029, \tloss: 0.8608, \taccuracy: 0.7589\n",
            "epoch: 030, \tloss: 0.8646, \taccuracy: 0.7679\n",
            "epoch: 031, \tloss: 0.8715, \taccuracy: 0.7054\n",
            "epoch: 032, \tloss: 0.827, \taccuracy: 0.7946\n",
            "epoch: 033, \tloss: 0.8876, \taccuracy: 0.6964\n",
            "epoch: 034, \tloss: 0.8568, \taccuracy: 0.6786\n",
            "epoch: 035, \tloss: 0.8047, \taccuracy: 0.7589\n",
            "epoch: 036, \tloss: 0.839, \taccuracy: 0.7232\n",
            "epoch: 037, \tloss: 0.8317, \taccuracy: 0.7232\n",
            "epoch: 038, \tloss: 0.7842, \taccuracy: 0.7768\n",
            "epoch: 039, \tloss: 0.8284, \taccuracy: 0.7232\n",
            "epoch: 040, \tloss: 0.8415, \taccuracy: 0.6786\n",
            "epoch: 041, \tloss: 0.7887, \taccuracy: 0.7679\n",
            "epoch: 042, \tloss: 0.7854, \taccuracy: 0.7411\n",
            "epoch: 043, \tloss: 0.8122, \taccuracy: 0.7768\n",
            "epoch: 044, \tloss: 0.8037, \taccuracy: 0.7679\n",
            "epoch: 045, \tloss: 0.76, \taccuracy: 0.75\n",
            "epoch: 046, \tloss: 0.7672, \taccuracy: 0.7679\n",
            "epoch: 047, \tloss: 0.7806, \taccuracy: 0.7411\n",
            "epoch: 048, \tloss: 0.7635, \taccuracy: 0.7411\n",
            "epoch: 049, \tloss: 0.7629, \taccuracy: 0.8036\n",
            "epoch: 050, \tloss: 0.7158, \taccuracy: 0.7857\n",
            "epoch: 051, \tloss: 0.7494, \taccuracy: 0.7589\n",
            "epoch: 052, \tloss: 0.7854, \taccuracy: 0.75\n",
            "epoch: 053, \tloss: 0.7352, \taccuracy: 0.7411\n",
            "epoch: 054, \tloss: 0.708, \taccuracy: 0.7857\n",
            "epoch: 055, \tloss: 0.7756, \taccuracy: 0.6875\n",
            "epoch: 056, \tloss: 0.7395, \taccuracy: 0.75\n",
            "epoch: 057, \tloss: 0.7607, \taccuracy: 0.7411\n",
            "epoch: 058, \tloss: 0.744, \taccuracy: 0.75\n",
            "epoch: 059, \tloss: 0.658, \taccuracy: 0.8393\n",
            "epoch: 060, \tloss: 0.7167, \taccuracy: 0.7321\n",
            "epoch: 061, \tloss: 0.6506, \taccuracy: 0.8125\n",
            "epoch: 062, \tloss: 0.7654, \taccuracy: 0.6786\n",
            "epoch: 063, \tloss: 0.682, \taccuracy: 0.7857\n",
            "epoch: 064, \tloss: 0.6773, \taccuracy: 0.7946\n",
            "epoch: 065, \tloss: 0.6973, \taccuracy: 0.7768\n",
            "epoch: 066, \tloss: 0.6523, \taccuracy: 0.7946\n",
            "epoch: 067, \tloss: 0.6736, \taccuracy: 0.7857\n",
            "epoch: 068, \tloss: 0.7265, \taccuracy: 0.7321\n",
            "epoch: 069, \tloss: 0.6834, \taccuracy: 0.7946\n",
            "epoch: 070, \tloss: 0.645, \taccuracy: 0.7946\n",
            "epoch: 071, \tloss: 0.6145, \taccuracy: 0.8304\n",
            "epoch: 072, \tloss: 0.6716, \taccuracy: 0.7321\n",
            "epoch: 073, \tloss: 0.7333, \taccuracy: 0.7143\n",
            "epoch: 074, \tloss: 0.6084, \taccuracy: 0.8214\n",
            "epoch: 075, \tloss: 0.642, \taccuracy: 0.8036\n",
            "epoch: 076, \tloss: 0.6115, \taccuracy: 0.8304\n",
            "epoch: 077, \tloss: 0.6446, \taccuracy: 0.7589\n",
            "epoch: 078, \tloss: 0.6652, \taccuracy: 0.8036\n",
            "epoch: 079, \tloss: 0.6582, \taccuracy: 0.7679\n",
            "epoch: 080, \tloss: 0.722, \taccuracy: 0.6607\n",
            "epoch: 081, \tloss: 0.6203, \taccuracy: 0.7946\n",
            "epoch: 082, \tloss: 0.6851, \taccuracy: 0.7232\n",
            "epoch: 083, \tloss: 0.6158, \taccuracy: 0.7589\n",
            "epoch: 084, \tloss: 0.6234, \taccuracy: 0.8214\n",
            "epoch: 085, \tloss: 0.5947, \taccuracy: 0.8304\n",
            "epoch: 086, \tloss: 0.6108, \taccuracy: 0.7946\n",
            "epoch: 087, \tloss: 0.6372, \taccuracy: 0.7768\n",
            "epoch: 088, \tloss: 0.5373, \taccuracy: 0.8571\n",
            "epoch: 089, \tloss: 0.7141, \taccuracy: 0.7321\n",
            "epoch: 090, \tloss: 0.6282, \taccuracy: 0.7946\n",
            "epoch: 091, \tloss: 0.6127, \taccuracy: 0.7946\n",
            "epoch: 092, \tloss: 0.6082, \taccuracy: 0.7857\n",
            "epoch: 093, \tloss: 0.5824, \taccuracy: 0.8125\n",
            "epoch: 094, \tloss: 0.5587, \taccuracy: 0.8571\n",
            "epoch: 095, \tloss: 0.6158, \taccuracy: 0.7768\n",
            "epoch: 096, \tloss: 0.5797, \taccuracy: 0.7946\n",
            "epoch: 097, \tloss: 0.6315, \taccuracy: 0.7768\n",
            "epoch: 098, \tloss: 0.5582, \taccuracy: 0.8304\n",
            "epoch: 099, \tloss: 0.6577, \taccuracy: 0.7321\n",
            "epoch: 100, \tloss: 0.6527, \taccuracy: 0.6964\n",
            "epoch: 101, \tloss: 0.558, \taccuracy: 0.8125\n",
            "epoch: 102, \tloss: 0.5893, \taccuracy: 0.7946\n",
            "epoch: 103, \tloss: 0.5986, \taccuracy: 0.7857\n",
            "epoch: 104, \tloss: 0.5144, \taccuracy: 0.8214\n",
            "epoch: 105, \tloss: 0.5824, \taccuracy: 0.7857\n",
            "epoch: 106, \tloss: 0.6122, \taccuracy: 0.7411\n",
            "epoch: 107, \tloss: 0.5384, \taccuracy: 0.8214\n",
            "epoch: 108, \tloss: 0.5738, \taccuracy: 0.8125\n",
            "epoch: 109, \tloss: 0.5603, \taccuracy: 0.8393\n",
            "epoch: 110, \tloss: 0.5957, \taccuracy: 0.7589\n",
            "epoch: 111, \tloss: 0.5131, \taccuracy: 0.8036\n",
            "epoch: 112, \tloss: 0.5881, \taccuracy: 0.7857\n",
            "epoch: 113, \tloss: 0.571, \taccuracy: 0.7679\n",
            "epoch: 114, \tloss: 0.4998, \taccuracy: 0.8214\n",
            "epoch: 115, \tloss: 0.5119, \taccuracy: 0.8304\n",
            "epoch: 116, \tloss: 0.5858, \taccuracy: 0.7411\n",
            "epoch: 117, \tloss: 0.5321, \taccuracy: 0.7946\n",
            "epoch: 118, \tloss: 0.519, \taccuracy: 0.8125\n",
            "epoch: 119, \tloss: 0.587, \taccuracy: 0.75\n",
            "epoch: 120, \tloss: 0.5579, \taccuracy: 0.7857\n",
            "epoch: 121, \tloss: 0.6005, \taccuracy: 0.75\n",
            "epoch: 122, \tloss: 0.5406, \taccuracy: 0.7946\n",
            "epoch: 123, \tloss: 0.4819, \taccuracy: 0.8482\n",
            "epoch: 124, \tloss: 0.4818, \taccuracy: 0.8482\n",
            "epoch: 125, \tloss: 0.6059, \taccuracy: 0.75\n",
            "epoch: 126, \tloss: 0.5937, \taccuracy: 0.7321\n",
            "epoch: 127, \tloss: 0.4691, \taccuracy: 0.8571\n",
            "epoch: 128, \tloss: 0.5367, \taccuracy: 0.8482\n",
            "epoch: 129, \tloss: 0.4923, \taccuracy: 0.8661\n",
            "epoch: 130, \tloss: 0.5528, \taccuracy: 0.75\n",
            "epoch: 131, \tloss: 0.448, \taccuracy: 0.8571\n",
            "epoch: 132, \tloss: 0.479, \taccuracy: 0.8304\n",
            "epoch: 133, \tloss: 0.466, \taccuracy: 0.8482\n",
            "epoch: 134, \tloss: 0.499, \taccuracy: 0.8036\n",
            "epoch: 135, \tloss: 0.4743, \taccuracy: 0.8482\n",
            "epoch: 136, \tloss: 0.5409, \taccuracy: 0.7857\n",
            "epoch: 137, \tloss: 0.59, \taccuracy: 0.7411\n",
            "epoch: 138, \tloss: 0.5884, \taccuracy: 0.7589\n",
            "epoch: 139, \tloss: 0.4464, \taccuracy: 0.8482\n",
            "epoch: 140, \tloss: 0.5817, \taccuracy: 0.7054\n",
            "epoch: 141, \tloss: 0.5385, \taccuracy: 0.8036\n",
            "epoch: 142, \tloss: 0.5187, \taccuracy: 0.8393\n",
            "epoch: 143, \tloss: 0.5127, \taccuracy: 0.8214\n",
            "epoch: 144, \tloss: 0.4844, \taccuracy: 0.8393\n",
            "epoch: 145, \tloss: 0.5341, \taccuracy: 0.7768\n",
            "epoch: 146, \tloss: 0.4995, \taccuracy: 0.7857\n",
            "epoch: 147, \tloss: 0.4298, \taccuracy: 0.8661\n",
            "epoch: 148, \tloss: 0.519, \taccuracy: 0.7946\n",
            "epoch: 149, \tloss: 0.5635, \taccuracy: 0.7589\n",
            "epoch: 150, \tloss: 0.4551, \taccuracy: 0.8482\n",
            "epoch: 151, \tloss: 0.6264, \taccuracy: 0.7143\n",
            "epoch: 152, \tloss: 0.5049, \taccuracy: 0.7857\n",
            "epoch: 153, \tloss: 0.5655, \taccuracy: 0.7589\n",
            "epoch: 154, \tloss: 0.4867, \taccuracy: 0.8214\n",
            "epoch: 155, \tloss: 0.5397, \taccuracy: 0.75\n",
            "epoch: 156, \tloss: 0.5497, \taccuracy: 0.8304\n",
            "epoch: 157, \tloss: 0.4909, \taccuracy: 0.8482\n",
            "epoch: 158, \tloss: 0.3905, \taccuracy: 0.875\n",
            "epoch: 159, \tloss: 0.4199, \taccuracy: 0.8482\n",
            "epoch: 160, \tloss: 0.5066, \taccuracy: 0.7857\n",
            "epoch: 161, \tloss: 0.4384, \taccuracy: 0.8571\n",
            "epoch: 162, \tloss: 0.4027, \taccuracy: 0.8571\n",
            "epoch: 163, \tloss: 0.4553, \taccuracy: 0.8393\n",
            "epoch: 164, \tloss: 0.485, \taccuracy: 0.8036\n",
            "epoch: 165, \tloss: 0.4203, \taccuracy: 0.8482\n",
            "epoch: 166, \tloss: 0.4845, \taccuracy: 0.8214\n",
            "epoch: 167, \tloss: 0.4299, \taccuracy: 0.8304\n",
            "epoch: 168, \tloss: 0.3885, \taccuracy: 0.8839\n",
            "epoch: 169, \tloss: 0.4276, \taccuracy: 0.8661\n",
            "epoch: 170, \tloss: 0.4595, \taccuracy: 0.8125\n",
            "epoch: 171, \tloss: 0.4961, \taccuracy: 0.8125\n",
            "epoch: 172, \tloss: 0.4759, \taccuracy: 0.8393\n",
            "epoch: 173, \tloss: 0.5018, \taccuracy: 0.7857\n",
            "epoch: 174, \tloss: 0.3843, \taccuracy: 0.8929\n",
            "epoch: 175, \tloss: 0.3704, \taccuracy: 0.875\n",
            "epoch: 176, \tloss: 0.3753, \taccuracy: 0.8661\n",
            "epoch: 177, \tloss: 0.4329, \taccuracy: 0.8482\n",
            "epoch: 178, \tloss: 0.4645, \taccuracy: 0.8482\n",
            "epoch: 179, \tloss: 0.489, \taccuracy: 0.7768\n",
            "epoch: 180, \tloss: 0.3289, \taccuracy: 0.875\n",
            "epoch: 181, \tloss: 0.4257, \taccuracy: 0.8661\n",
            "epoch: 182, \tloss: 0.4179, \taccuracy: 0.8661\n",
            "epoch: 183, \tloss: 0.4839, \taccuracy: 0.8125\n",
            "epoch: 184, \tloss: 0.4168, \taccuracy: 0.8482\n",
            "epoch: 185, \tloss: 0.4397, \taccuracy: 0.8304\n",
            "epoch: 186, \tloss: 0.5166, \taccuracy: 0.7857\n",
            "epoch: 187, \tloss: 0.5226, \taccuracy: 0.7768\n",
            "epoch: 188, \tloss: 0.4505, \taccuracy: 0.8393\n",
            "epoch: 189, \tloss: 0.4408, \taccuracy: 0.8393\n",
            "epoch: 190, \tloss: 0.3667, \taccuracy: 0.875\n",
            "epoch: 191, \tloss: 0.4356, \taccuracy: 0.8571\n",
            "epoch: 192, \tloss: 0.4744, \taccuracy: 0.7946\n",
            "epoch: 193, \tloss: 0.3678, \taccuracy: 0.8929\n",
            "epoch: 194, \tloss: 0.6034, \taccuracy: 0.7679\n",
            "epoch: 195, \tloss: 0.3871, \taccuracy: 0.9018\n",
            "epoch: 196, \tloss: 0.4262, \taccuracy: 0.8482\n",
            "epoch: 197, \tloss: 0.4201, \taccuracy: 0.8304\n",
            "epoch: 198, \tloss: 0.4488, \taccuracy: 0.8125\n",
            "epoch: 199, \tloss: 0.4823, \taccuracy: 0.8304\n",
            "epoch: 200, \tloss: 0.4949, \taccuracy: 0.8304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEWM2lxBmE7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}