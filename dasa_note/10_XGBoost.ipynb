{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 장점\n",
    "    * 예측 속도가 상당히 빠르며, 예측력 또한 좋다.\n",
    "    * 변수 종류가 많고 데이터가 클수록 상대적으로 뛰어난 성능을 보인다.\n",
    "* 단점\n",
    "    * 복잡한 모델인 만큼, 해석에 어려움이 있다.\n",
    "    * 더 나은 성능을 위한 하이퍼파라미터 튜닝이 까다롭다.\n",
    "\n",
    "* 종속변수가 연속형 데이터인 경우든 범주형 데이터인 경우든 모두 사용할 수 있다.\n",
    "* 이미지나 자연어가 아닌 표로 정리된 데이터의 경우, 거의 모든 상황에 활용할 수  있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 문제 정의 : 한눈에 보는 예측 목표\n",
    "\n",
    "* 미션: 스피드데이팅 데이터셋을 이용해서 커플 성사 여부를 예측하라\n",
    "* 알고리즘 : XG부스트(XGBoost)\n",
    "* 문제 유형: 분류\n",
    "* 평가 지표: 정확도, 혼동 행렬, 분류 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_url = 'https://media.githubusercontent.com/media/musthave-ML10/data_source/main/dating.csv'\n",
    "data = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>...</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Asian/PacificIslander/Asian-American</td>\n",
       "      <td>Latino/HispanicAmerican</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_null  gender   age  age_o                                  race  \\\n",
       "0         0  female  21.0   27.0  Asian/PacificIslander/Asian-American   \n",
       "1         0  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "2         1  female  21.0   22.0  Asian/PacificIslander/Asian-American   \n",
       "3         0  female  21.0   23.0  Asian/PacificIslander/Asian-American   \n",
       "4         0  female  21.0   24.0  Asian/PacificIslander/Asian-American   \n",
       "\n",
       "                                 race_o  importance_same_race  \\\n",
       "0           European/Caucasian-American                   2.0   \n",
       "1           European/Caucasian-American                   2.0   \n",
       "2  Asian/PacificIslander/Asian-American                   2.0   \n",
       "3           European/Caucasian-American                   2.0   \n",
       "4               Latino/HispanicAmerican                   2.0   \n",
       "\n",
       "   importance_same_religion  pref_o_attractive  pref_o_sincere  ...  \\\n",
       "0                       4.0               35.0            20.0  ...   \n",
       "1                       4.0               60.0             0.0  ...   \n",
       "2                       4.0               19.0            18.0  ...   \n",
       "3                       4.0               30.0             5.0  ...   \n",
       "4                       4.0               30.0            10.0  ...   \n",
       "\n",
       "   funny_partner  ambition_partner  shared_interests_partner  \\\n",
       "0            7.0               6.0                       5.0   \n",
       "1            8.0               5.0                       6.0   \n",
       "2            8.0               5.0                       7.0   \n",
       "3            7.0               6.0                       8.0   \n",
       "4            7.0               6.0                       6.0   \n",
       "\n",
       "   interests_correlate  expected_happy_with_sd_people  \\\n",
       "0                 0.14                            3.0   \n",
       "1                 0.54                            3.0   \n",
       "2                 0.16                            3.0   \n",
       "3                 0.61                            3.0   \n",
       "4                 0.21                            3.0   \n",
       "\n",
       "   expected_num_interested_in_me  like  guess_prob_liked  met  match  \n",
       "0                            2.0   7.0               6.0  0.0      0  \n",
       "1                            2.0   7.0               5.0  1.0      0  \n",
       "2                            2.0   7.0               NaN  1.0      1  \n",
       "3                            2.0   7.0               6.0  0.0      1  \n",
       "4                            2.0   6.0               6.0  0.0      1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   has_null                       8378 non-null   int64  \n",
      " 1   gender                         8378 non-null   object \n",
      " 2   age                            8283 non-null   float64\n",
      " 3   age_o                          8274 non-null   float64\n",
      " 4   race                           8315 non-null   object \n",
      " 5   race_o                         8305 non-null   object \n",
      " 6   importance_same_race           8299 non-null   float64\n",
      " 7   importance_same_religion       8299 non-null   float64\n",
      " 8   pref_o_attractive              8289 non-null   float64\n",
      " 9   pref_o_sincere                 8289 non-null   float64\n",
      " 10  pref_o_intelligence            8289 non-null   float64\n",
      " 11  pref_o_funny                   8280 non-null   float64\n",
      " 12  pref_o_ambitious               8271 non-null   float64\n",
      " 13  pref_o_shared_interests        8249 non-null   float64\n",
      " 14  attractive_o                   8166 non-null   float64\n",
      " 15  sincere_o                      8091 non-null   float64\n",
      " 16  intelligence_o                 8072 non-null   float64\n",
      " 17  funny_o                        8018 non-null   float64\n",
      " 18  ambitous_o                     7656 non-null   float64\n",
      " 19  shared_interests_o             7302 non-null   float64\n",
      " 20  attractive_important           8299 non-null   float64\n",
      " 21  sincere_important              8299 non-null   float64\n",
      " 22  intellicence_important         8299 non-null   float64\n",
      " 23  funny_important                8289 non-null   float64\n",
      " 24  ambtition_important            8279 non-null   float64\n",
      " 25  shared_interests_important     8257 non-null   float64\n",
      " 26  attractive_partner             8176 non-null   float64\n",
      " 27  sincere_partner                8101 non-null   float64\n",
      " 28  intelligence_partner           8082 non-null   float64\n",
      " 29  funny_partner                  8028 non-null   float64\n",
      " 30  ambition_partner               7666 non-null   float64\n",
      " 31  shared_interests_partner       7311 non-null   float64\n",
      " 32  interests_correlate            8220 non-null   float64\n",
      " 33  expected_happy_with_sd_people  8277 non-null   float64\n",
      " 34  expected_num_interested_in_me  1800 non-null   float64\n",
      " 35  like                           8138 non-null   float64\n",
      " 36  guess_prob_liked               8069 non-null   float64\n",
      " 37  met                            8003 non-null   float64\n",
      " 38  match                          8378 non-null   int64  \n",
      "dtypes: float64(34), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>pref_o_shared_interests</th>\n",
       "      <th>attractive_o</th>\n",
       "      <th>sincere_o</th>\n",
       "      <th>intelligence_o</th>\n",
       "      <th>funny_o</th>\n",
       "      <th>ambitous_o</th>\n",
       "      <th>shared_interests_o</th>\n",
       "      <th>attractive_important</th>\n",
       "      <th>sincere_important</th>\n",
       "      <th>intellicence_important</th>\n",
       "      <th>funny_important</th>\n",
       "      <th>ambtition_important</th>\n",
       "      <th>shared_interests_important</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>shared_interests_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.00</td>\n",
       "      <td>8283.00</td>\n",
       "      <td>8274.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8280.00</td>\n",
       "      <td>8271.00</td>\n",
       "      <td>8249.00</td>\n",
       "      <td>8166.00</td>\n",
       "      <td>8091.00</td>\n",
       "      <td>8072.00</td>\n",
       "      <td>8018.00</td>\n",
       "      <td>7656.00</td>\n",
       "      <td>7302.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>8289.00</td>\n",
       "      <td>8279.00</td>\n",
       "      <td>8257.00</td>\n",
       "      <td>8176.00</td>\n",
       "      <td>8101.00</td>\n",
       "      <td>8082.00</td>\n",
       "      <td>8028.00</td>\n",
       "      <td>7666.00</td>\n",
       "      <td>7311.00</td>\n",
       "      <td>8220.00</td>\n",
       "      <td>8277.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>8138.00</td>\n",
       "      <td>8069.00</td>\n",
       "      <td>8003.00</td>\n",
       "      <td>8378.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.87</td>\n",
       "      <td>26.36</td>\n",
       "      <td>26.36</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.65</td>\n",
       "      <td>22.50</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>22.51</td>\n",
       "      <td>17.40</td>\n",
       "      <td>20.27</td>\n",
       "      <td>17.46</td>\n",
       "      <td>10.68</td>\n",
       "      <td>11.85</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.18</td>\n",
       "      <td>7.37</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.78</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.33</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.81</td>\n",
       "      <td>12.57</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>12.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.73</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>17.39</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.37</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_null      age    age_o  importance_same_race  \\\n",
       "count   8378.00  8283.00  8274.00               8299.00   \n",
       "mean       0.87    26.36    26.36                  3.78   \n",
       "std        0.33     3.57     3.56                  2.85   \n",
       "min        0.00    18.00    18.00                  0.00   \n",
       "25%        1.00    24.00    24.00                  1.00   \n",
       "50%        1.00    26.00    26.00                  3.00   \n",
       "75%        1.00    28.00    28.00                  6.00   \n",
       "max        1.00    55.00    55.00                 10.00   \n",
       "\n",
       "       importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "count                   8299.00            8289.00         8289.00   \n",
       "mean                       3.65              22.50           17.40   \n",
       "std                        2.81              12.57            7.04   \n",
       "min                        1.00               0.00            0.00   \n",
       "25%                        1.00              15.00           15.00   \n",
       "50%                        3.00              20.00           18.37   \n",
       "75%                        6.00              25.00           20.00   \n",
       "max                       10.00             100.00           60.00   \n",
       "\n",
       "       pref_o_intelligence  pref_o_funny  pref_o_ambitious  \\\n",
       "count              8289.00       8280.00           8271.00   \n",
       "mean                 20.27         17.46             10.69   \n",
       "std                   6.78          6.09              6.13   \n",
       "min                   0.00          0.00              0.00   \n",
       "25%                  17.39         15.00              5.00   \n",
       "50%                  20.00         18.00             10.00   \n",
       "75%                  23.81         20.00             15.00   \n",
       "max                  50.00         50.00             53.00   \n",
       "\n",
       "       pref_o_shared_interests  attractive_o  sincere_o  intelligence_o  \\\n",
       "count                  8249.00       8166.00    8091.00         8072.00   \n",
       "mean                     11.85          6.19       7.18            7.37   \n",
       "std                       6.36          1.95       1.74            1.55   \n",
       "min                       0.00          0.00       0.00            0.00   \n",
       "25%                       9.52          5.00       6.00            6.00   \n",
       "50%                      10.64          6.00       7.00            7.00   \n",
       "75%                      16.00          8.00       8.00            8.00   \n",
       "max                      30.00         10.50      10.00           10.00   \n",
       "\n",
       "       funny_o  ambitous_o  shared_interests_o  attractive_important  \\\n",
       "count  8018.00     7656.00             7302.00               8299.00   \n",
       "mean      6.40        6.78                5.47                 22.51   \n",
       "std       1.95        1.79                2.16                 12.59   \n",
       "min       0.00        0.00                0.00                  0.00   \n",
       "25%       5.00        6.00                4.00                 15.00   \n",
       "50%       7.00        7.00                6.00                 20.00   \n",
       "75%       8.00        8.00                7.00                 25.00   \n",
       "max      11.00       10.00               10.00                100.00   \n",
       "\n",
       "       sincere_important  intellicence_important  funny_important  \\\n",
       "count            8299.00                 8299.00          8289.00   \n",
       "mean               17.40                   20.27            17.46   \n",
       "std                 7.05                    6.78             6.09   \n",
       "min                 0.00                    0.00             0.00   \n",
       "25%                15.00                   17.39            15.00   \n",
       "50%                18.18                   20.00            18.00   \n",
       "75%                20.00                   23.81            20.00   \n",
       "max                60.00                   50.00            50.00   \n",
       "\n",
       "       ambtition_important  shared_interests_important  attractive_partner  \\\n",
       "count              8279.00                     8257.00             8176.00   \n",
       "mean                 10.68                       11.85                6.19   \n",
       "std                   6.12                        6.36                1.95   \n",
       "min                   0.00                        0.00                0.00   \n",
       "25%                   5.00                        9.52                5.00   \n",
       "50%                  10.00                       10.64                6.00   \n",
       "75%                  15.00                       16.00                8.00   \n",
       "max                  53.00                       30.00               10.00   \n",
       "\n",
       "       sincere_partner  intelligence_partner  funny_partner  ambition_partner  \\\n",
       "count          8101.00               8082.00        8028.00           7666.00   \n",
       "mean              7.18                  7.37           6.40              6.78   \n",
       "std               1.74                  1.55           1.95              1.79   \n",
       "min               0.00                  0.00           0.00              0.00   \n",
       "25%               6.00                  6.00           5.00              6.00   \n",
       "50%               7.00                  7.00           7.00              7.00   \n",
       "75%               8.00                  8.00           8.00              8.00   \n",
       "max              10.00                 10.00          10.00             10.00   \n",
       "\n",
       "       shared_interests_partner  interests_correlate  \\\n",
       "count                   7311.00              8220.00   \n",
       "mean                       5.47                 0.20   \n",
       "std                        2.16                 0.30   \n",
       "min                        0.00                -0.83   \n",
       "25%                        4.00                -0.02   \n",
       "50%                        6.00                 0.21   \n",
       "75%                        7.00                 0.43   \n",
       "max                       10.00                 0.91   \n",
       "\n",
       "       expected_happy_with_sd_people  expected_num_interested_in_me     like  \\\n",
       "count                        8277.00                        1800.00  8138.00   \n",
       "mean                            5.53                           5.57     6.13   \n",
       "std                             1.73                           4.76     1.84   \n",
       "min                             1.00                           0.00     0.00   \n",
       "25%                             5.00                           2.00     5.00   \n",
       "50%                             6.00                           4.00     6.00   \n",
       "75%                             7.00                           8.00     7.00   \n",
       "max                            10.00                          20.00    10.00   \n",
       "\n",
       "       guess_prob_liked      met    match  \n",
       "count           8069.00  8003.00  8378.00  \n",
       "mean               5.21     0.05     0.16  \n",
       "std                2.13     0.28     0.37  \n",
       "min                0.00     0.00     0.00  \n",
       "25%                4.00     0.00     0.00  \n",
       "50%                5.00     0.00     0.00  \n",
       "75%                7.00     0.00     0.00  \n",
       "max               10.00     8.00     1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_null                         0.000000\n",
       "gender                           0.000000\n",
       "age                              0.011339\n",
       "age_o                            0.012413\n",
       "race                             0.007520\n",
       "race_o                           0.008713\n",
       "importance_same_race             0.009429\n",
       "importance_same_religion         0.009429\n",
       "pref_o_attractive                0.010623\n",
       "pref_o_sincere                   0.010623\n",
       "pref_o_intelligence              0.010623\n",
       "pref_o_funny                     0.011697\n",
       "pref_o_ambitious                 0.012772\n",
       "pref_o_shared_interests          0.015397\n",
       "attractive_o                     0.025304\n",
       "sincere_o                        0.034256\n",
       "intelligence_o                   0.036524\n",
       "funny_o                          0.042970\n",
       "ambitous_o                       0.086178\n",
       "shared_interests_o               0.128432\n",
       "attractive_important             0.009429\n",
       "sincere_important                0.009429\n",
       "intellicence_important           0.009429\n",
       "funny_important                  0.010623\n",
       "ambtition_important              0.011817\n",
       "shared_interests_important       0.014443\n",
       "attractive_partner               0.024111\n",
       "sincere_partner                  0.033063\n",
       "intelligence_partner             0.035331\n",
       "funny_partner                    0.041776\n",
       "ambition_partner                 0.084984\n",
       "shared_interests_partner         0.127357\n",
       "interests_correlate              0.018859\n",
       "expected_happy_with_sd_people    0.012055\n",
       "expected_num_interested_in_me    0.785152\n",
       "like                             0.028646\n",
       "guess_prob_liked                 0.036882\n",
       "met                              0.044760\n",
       "match                            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 제거\n",
    "data = data.dropna(subset=['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', 'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests','attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important', 'shared_interests_important'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(-99) # 남은 결측치는 -99로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 전처리 : 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gap(x):\n",
    "    if x['age'] == -99:\n",
    "        return -99\n",
    "    elif x['age_o'] == -99:\n",
    "        return -99\n",
    "    elif x['gender'] == 'female':\n",
    "        return x['age_o'] - x['age']\n",
    "    else:\n",
    "        x['age'] - x['age_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_gap'] = data.apply(age_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_gap_abs'] = abs(data['age_gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race(x):\n",
    "    if x['race'] == -99:\n",
    "        return -99\n",
    "    elif x['race_o'] == -99:\n",
    "        return -99\n",
    "    elif x['race'] == x['race_o']:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['same_race'] = data.apply(same_race, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race_point(x):\n",
    "    if x['same_race'] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return x['same_race'] * x['importance_same_race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['same_race_point'] = data.apply(same_race_point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(data, importance, score):\n",
    "    if data[importance] == -99:\n",
    "        return -99\n",
    "    elif data[score] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return data[importance] * data[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
       "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[8:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_imp = data.columns[8:14] # 상대방의 중요도\n",
    "partner_rate_me = data.columns[14:20] # 본인에 대한 상대방의 평가\n",
    "my_imp = data.columns[20:26] # 본인의 중요도\n",
    "my_rate_partner = data.columns[26:32] # 상대방에 대한 본인의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상대방 관련 새 변수 이름 리스트\n",
    "new_label_partner = ['attractive_p', 'sincere_partner_p', 'intelligence_p', 'funny_p', 'ambition_p', 'shared_interests_p']\n",
    "# 본인 관련 새 변수 이름 리스트\n",
    "new_label_me = ['attractive_m', 'sincere_partner_m', 'intelligence_m', 'funny_m', 'ambition_m', 'shared_interests_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(new_label_partner, partner_imp, partner_rate_me):\n",
    "    data[i] = data.apply(lambda x: rating(x, j, k), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(new_label_me, my_imp, my_rate_partner):\n",
    "    data[i] = data.apply(lambda x: rating(x, j, k), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['gender', 'race', 'race_o'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 모델링 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('match', axis=1),  data['match'], test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hansanghui/opt/anaconda3/envs/myenv1/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hansanghui/opt/anaconda3/envs/myenv1/lib/python3.8/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:31:21] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653136531365314"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1292   73]\n",
      " [ 146  115]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6790\n",
       "1    1340\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1365\n",
      "           1       0.61      0.44      0.51       261\n",
      "\n",
      "    accuracy                           0.87      1626\n",
      "   macro avg       0.76      0.69      0.72      1626\n",
      "weighted avg       0.85      0.87      0.86      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정밀도(precision)  \n",
    "$TP \\over TP + FP$  \n",
    "1종 오류와 관련, 실제로 1로 예측한 경우, 얼마만큼이 실제로 1인지를 나타냄.\n",
    "\n",
    "* 재현율(recall)  \n",
    "$TP \\over TP + FN $  \n",
    "2종 오류와 관련, 실제로 1중에, 얼마만큼 1로 예측을 했는지 나타냄\n",
    "\n",
    "* F1 score\n",
    "정밀도와 재현율의 조화 평균  \n",
    "$2 * (precision * recall) \\over (precision + recall)$  \n",
    "\n",
    "* 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [3, 5, 10]\n",
    "learning_rate = [0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth' : [5, 7, 10],\n",
    "    'subsample' : [0.5, 0.7, 1],\n",
    "    'n_estimators': [300, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model = GridSearchCV(model, parameters, n_jobs=-1, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- gs_model.fit(X_train, y_train) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = gs_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 중요 변수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=1000, subsample=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hansanghui/opt/anaconda3/envs/myenv1/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hansanghui/opt/anaconda3/envs/myenv1/lib/python3.8/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:13:53] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=1000, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=1000, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=10,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=100,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0100628 , 0.01232549, 0.00912444, 0.01019195, 0.01094785,\n",
       "       0.01350423, 0.01381248, 0.01573691, 0.01135239, 0.01377819,\n",
       "       0.01703993, 0.04676888, 0.01436752, 0.01758111, 0.02778915,\n",
       "       0.01365067, 0.02236081, 0.0160435 , 0.01396238, 0.01612994,\n",
       "       0.01264793, 0.01414683, 0.01316356, 0.02768657, 0.01535979,\n",
       "       0.01266819, 0.0298027 , 0.01809027, 0.01769027, 0.01232217,\n",
       "       0.01013115, 0.0203734 , 0.05285272, 0.02168748, 0.0222656 ,\n",
       "       0.01077087, 0.01189536, 0.01059534, 0.01485658, 0.01212148,\n",
       "       0.01304964, 0.01487633, 0.01434289, 0.01113706, 0.00954705,\n",
       "       0.01192562, 0.01291426, 0.01285523, 0.01193985, 0.0132804 ,\n",
       "       0.00969376, 0.        , 0.02191566, 0.01024889, 0.04497222,\n",
       "       0.0333662 , 0.02205783, 0.01300397, 0.02092846, 0.01028584],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame({'features': X_train.columns, 'values': model.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_null</td>\n",
       "      <td>0.010063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.012325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_o</td>\n",
       "      <td>0.009124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>importance_same_race</td>\n",
       "      <td>0.010192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>importance_same_religion</td>\n",
       "      <td>0.010948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features    values\n",
       "0                  has_null  0.010063\n",
       "1                       age  0.012325\n",
       "2                     age_o  0.009124\n",
       "3      importance_same_race  0.010192\n",
       "4  importance_same_religion  0.010948"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='values', ylabel='features'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRYAAAJNCAYAAABENSlkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8kElEQVR4nO3de7gmVXkn7N8jjYKAEAUdNGqjARQQEQFFDWLCRzwkEiORMRqDmqDxmMwYv4yOBnU08RQTTzFoPKCMp3gIJjOC8cQERaChaUBAo2CiMp8aEAUUFZ/vj7fQ13bv7l29D+/u5r6vq69d73pXrXqqNnU1/Firqro7AAAAAABj3GLWBQAAAAAAWx/BIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKOtmXUBsJR23333Xrt27azLAAAAANhmrFu37lvdvcfG7YJFtilr167NueeeO+syAAAAALYZVfWVudothQYAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaF7ewjblkq/+R+77JyfPugwAAADgZmjdK58w6xJWlBmLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLrKiqunb4eceq+vth+/iqev1sKwMAAABgjDWzLoCbp+7+epJjZ10HAAAAAFvGjEVmoqrWVtVFc7Q/oqo+W1W7V9XRw/Z5VfX+qtp5FrUCAAAA8PMEi6waVfWoJH+a5OFD039PclR3H5zk3CT/ZVa1AQAAAPCzLIVmtXhIkkOSHN3d36mqX0+yX5IzqypJbpnks3PtWFUnJDkhSW65y+1WploAAACAmznBIqvFl5PcLck+mcxOrCQf6+7Hbm7H7j4pyUlJstN/2quXs0gAAAAAJiyFZrX4SpLfSnJyVe2f5KwkD6yqX0qSqrp1Ve0zywIBAAAA+CnBIqtGd1+W5HFJ3p/kNkmOT/LuqtqQSdB4j9lVBwAAAMA0S6FZUd298/DziiQHDNtvT/L2Yfv8TJ6tmCRfSnLoStcIAAAAwOaZsQgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjLZm1gXAUrrnL94u577yCbMuAwAAAGCbZ8YiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGG3NrAuApfSDKy/Ov734XrMuAwAAAH7GXV544axLgCVnxiIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbC4jauq501t71ZVT1vCsY+sqgdMfX5qVT1hqcYHAAAAYPUSLG77nje1vVuSOYPFqtpuC8Y+MslPgsXuflN3n7wF4wAAAACwlVkz6wJYOlX14SR3TrJDkr9OcrckO1bV+iQXJ9kuyd2Hzx9L8k9J/izJlUkOSrLfxmN090nD2A9N8rJhjG8leXKSpya5saoen+SZSX41ybXDuO/o7sOGfdcmObW7D6yq+yb5yyQ7D+Mc391XznM+ByV5U5JbJ/lSkid199WLvU4AAAAALJ5gcdvypO6+qqp2THJOkgcneUZ3H5T8JOA7YOrzkUkOG9oun2uMqvpAJjNb35zkiO6+vKpuO/R5U5Jru/tVw3i/miTdfUlV3bKq7tbdX05yXJL3VdX2SV6X5Jju/mZVHZfkpUmeNM/5nJzkmd396ap6cSYh6B9t3KmqTkhyQpLcadftt+jCAQAAADCOYHHb8qyqetSwfeckey9gn7OnQsX5xtgjyRk39evuqxYw7vuSPCbJX2QSLB6XZN8kByT5WFUlk9mP881W3DXJbt396aHpHUneP1ffYVblSUly4J127AXUBgAAAMAiCRa3EcPsw6OSHN7d11fVpzJZzrw51y1gjEoyNrB7b5L3V9UHk3R3f7Gq7pXk4u4+fORYAAAAAKwyXt6y7dg1ydVDIHiPJPcf2n84LEFOku8m2WULxvhskgdX1V5JUlW33dx43f2lJDcmeUEmIWOSXJZkj6o6fBhn+6raf579r0lydVX98tD0u0k+PVdfAAAAAFaeYHHb8dEka6pqQ5KXJDlraD8pyYaqOqW7/yPJmVV1UVW9cqFjdPc3M3mG4Qer6oL8NCj8SJJHVdX6qQBw2nuTPD6TZdHp7h8kOTbJy4dx1mfqrdJz+L0krxzqOSjJizd/GQAAAABYCdXtkXRsOw680479j0/5pVmXAQAAAD/jLi+8cNYlwBarqnXdfcjG7WYsAgAAAACjeXkLM1dVb0jywI2a/7q73zaLegAAAADYPMEiM9fdT591DQAAAACMYyk0AAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEZbM+sCYCndcs/9c5cXnjvrMgAAAAC2eWYsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNHWzLoAWEqXfuPSPPB1D5x1GQAAAMzYmc88c9YlwDbPjEUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAw2lYfLFbV2qq6aET/36yq/aY+v7iqjlrE8bevqnXD9rUbfXd8Vb1+2H5qVT1hS48zsqYFnVNV/XVVfa2qlu2fg5U8bwAAAABWzpqVOEhVVZLq7h+vxPE24zeT/GOSzydJd79wkeM9KMlnNtepu9+0yOMs2ELOaQgTH5Xk35MckeRTS11HVa1ZyfMGAAAAYOUs50y1tVV1SVW9Mcl5Sf6uqs6tqour6kVT/Q6tqs9U1QVVdXZV7VJV21XVK6vqnKraUFVP2YLj/8Gw/wVV9YGqunVVPSDJI5O8sqrWV9Xdq+rtVXXssM8VVfWiqjqvqi6sqnsM7betqg8PtZxVVQdOHeqhSf73Auo5saqeM2w/q6o+P4z3nqnv31lVn6iqL1bVHwztO1fVx6dqOmaj6/vm4ZqeXlU7Dt9Nn9PPXd+hpIckuSjJ3yR57EZ1vmMY74qq+q2qesVw7I9W1fZDv/tW1aeral1VnVZVew7tn6qql1XVp5M8e6Pz/qWq+uehlvOG6z/6/AAAAACYveVeCr1vkpO7+z5J/mt3H5LkwCQPrqoDq+qWSd6b5Nndfe8kRyX5XpInJ7mmuw9NcmiSP6iqvUYe+4Pdfegw7iVJntzdn0lyapI/6e6DuvtLc+z3re4+OJPA7TlD24uSnN/dByZ5XpKTp/o/JD+d7bfjEFiur6r1SV48T21/muQ+w3hPnWo/MMkjkhye5IVVdcck30/yqKGmhyR59TADNEn2TvKG7t4/ybeTPHr6IJu4vskkTHx3kg8l+fWbAsPB3Yc6jknyriSf7O57Dfs+Yuj7uiTHdvd9k7w1yUun9t+tux/c3a/e6LxPGeq9d5IHJLlyMec3dZ4nDKH1uT+89odzdQEAAABgiS33UuivdPdZw/ZjquqE4Zh7JtkvSSe5srvPSZLu/k6SVNXRSQ68adZdkl0zCZkuH3HsA6rqfyTZLcnOSU5b4H4fHH6uS/Jbw/aDMoRa3f2JqrpdVe2aZKckV3X39UO/73X3QTcNVFXHJzlkjmNsSHJKVX04yYen2v+hu7+X5HtV9ckkhyX5pyQvq6ojkvw4yZ2S3GHof3l3r5+qd+1Gx9k3c1/fWyZ5eJI/7u7vVtXnkhw9HCtJ/nd3/7CqLkyyXZKPDu0XDsfYN8kBST42ZIDbZRIS3uS9G5/wMFPyTt39oaGW7w/t2y/i/DKMdVKSk5Jk57vs3HP1AQAAAGBpLXeweF2SDLMNn5Pk0O6+uqrenmSHJJVJuLixSvLM7l5oGDiXtyf5ze6+YAj4jlzgfjcMP2/MT69PzdGvkzwsCw8spz0ik+caPjLJC6pq/6kxNz7G45LskeS+Q9h3RSbXbrrWm+rdeKnwfNf3oZmEtRcOweCtk1yfnwaLNyRJd/+4qn7Y3TeN8eNMrkklubi7D5/n/K6bo22ua5gs7vwAAAAAmJGVeiv0bTIJm66pqjtkEsglyaVJ7lhVhyaTWW1VtSaTsO4Pp57nt09V7TTymLskuXIY43FT7d8dvhvjjJvGqKojM1ku/Z0s8PmK02ry0pQ7d/cnkzw3P51RmSTHVNUOVXW7TILQczIJAL8xhG4PSXLXEYeb7/o+Nsnvd/fa7l6bZK8kR1fVrRc47mVJ9qiqw4dxt58KR+c0XK+vVtVvDvvcajjeYs4PAAAAgBlZkbdCD7MGz09ycZIvJzlzaP9BVR2X5HXDizm+l8lzAN+SybLX84bn7X0zk7c5z2ffqvrq1Oc/TvKCJJ9L8pVMlvDeFCa+J8mbq+pZSY7NwpyY5G1VtSGTmX2/V1XbJdm7uy9d4Bg32S7Ju4al1JXkNd397WHm4NmZzBq8S5KXdPfXq+qUJB+pqnOTrM8kLFyQea7v0Ul+LclTpvpdV1X/kuQ3Rox7bJLXDuexJslfZfL73ZTfTfK3VfXiJD9M8tuZPHdxi84PAAAAgNmpn65yZYyqelCSx3f3UzfbeWHjnZjk2u5+1VKMd3O181127nv/yb1nXQYAAAAzduYzz5x1CbDNqKp1w0uZf8aKzFjcFnX3vyT5l1nXAQAAAACzsNUEi1V1ryTv3Kj5hu6+3yzqWWrdfeKsawAAAACAhdpqgsXuvjDJQbOuAwAAAABYubdCAwAAAADbEMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEZbM+sCYCnd4/b3yJnPPHPWZQAAAABs88xYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKOtmXUBsJS+e9ll+fQRD551GQAA3Aw8+IxPz7oEAJgpMxYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiyxaVe1fVZ+oqi9U1Rer6gVVVcN3R1bVA6b6vr2qjp1dtQAAAAAsBcHizUBNLMvvuqp2THJqkr/o7n2S3DvJA5I8behy5PB5KY61bOcBAAAAwDhCmm1UVa2tqkuq6o1Jzkvyd1V1blVdXFUvmup3aFV9pqouqKqzq2qXqtquql5ZVedU1YaqesomDvU7Sc7s7tOTpLuvT/KMJH9aVWuTPDXJH1fV+qr65WGfI4Zjfnl69mJV/cnUMV80z3nceemuEgAAAABbas2sC2BZ7Zvkid39tKq6bXdfVVXbJfl4VR2Y5NIk701yXHefU1W3SfK9JE9Ock13H1pVt0pyZlWd3t2Xz3GM/ZOsm27o7i9V1c5JrkrypiTXdverkqSqnpxkzyQPSnKPTGY7/n1VHZ1k7ySHJakkp1bVEUn+bfo85jrJqjohyQlJcodb3WoLLxUAAAAAYwgWt21f6e6zhu3HDAHcmkyCvf2SdJIru/ucJOnu7yTJEPIdODWbcNdMQr+5gsUaxpnLfO0f7u4fJ/l8Vd1haDt6+HP+8Hnn4Zj/ttF5/PxBuk9KclKS7LvLLvMdEwAAAIAlJFjctl2XJFW1V5LnJDm0u6+uqrcn2SHzh4KV5JndfdoCjnFxkiN+Zuequ2UyS/G7wztcNnbDRse66eefd/ffbjTW2pvOAwAAAIDVwzMWbx5uk0k4d80wQ/BhQ/ulSe5YVYcmyfB8xTVJTkvyh1W1/dC+T1XtNM/YpyR5UFUdNfTdMclrk7xi+P67SXZZQI2nJXnSsIQ6VXWnqrr9yPMEAAAAYIWYsXgz0N0XVNX5mcwu/HKSM4f2H1TVcUleNwSC30tyVJK3JFmb5LyaTDn8ZpLfnGfs71XVMcMYb0iyXZJ3Jnn90OUjmTxD8Zgkz9xEjadX1T2TfHaY5XhtkscnuXERpw4AAADAMqluj6Rj27HvLrv0Sfc5eNZlAABwM/DgMz496xIAYEVU1bruPmTjdkuhAQAAAIDRLIVmQarqXpkscZ52Q3ffbxb1AAAAADBbgkUWpLsvTHLQrOsAAAAAYHWwFBoAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDR1sy6AFhKu+y7bx58xqdnXQYAAADANs+MRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADDamlkXAEvpG1+9Jq//rx+ZdRkAANuEZ7z6N2ZdAgCwipmxCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLK5iVfWsqrqkqk6ZdS1bqqqeN+saAAAAAFh6gsXV7WlJHt7dj5t1IWPVxC2SLFmwWFVrlmosAAAAABZHsLhKVdWbktwtyalVdU1VPWfqu4uqau3w55KqenNVXVxVp1fVjkOfT1XVy6vq7Kr6QlX98tD+f6rqoKmxzqyqA+ep4cSqemdVfaKqvlhVfzC071xVH6+q86rqwqo6Zmi/qZ43Jjkvyd8l2bGq1lfVKZup9+5V9dGqWjfUeI+h/e1V9ZdV9ckkL1/yCw0AAADAFhEsrlLd/dQkX0/ykCSv2UTXvZO8obv3T/LtJI+e+m5Ndx+W5I+S/NnQ9pYkxydJVe2T5FbdvWET4x+Y5BFJDk/ywqq6Y5LvJ3lUdx881Pfqqqqh/75JTu7u+3T3E5N8r7sPmpp1OV+9JyV5ZnffN8lzkrxxqoZ9khzV3f91rgKr6oSqOreqzr32+ms2cSoAAAAALBXB4tbv8u5eP2yvS7J26rsPztH+/iS/XlXbJ3lSkrdvZvx/6O7vdfe3knwyyWFJKsnLqmpDkn9Ocqckdxj6f6W7zxpTb1XtnOQBSd5fVeuT/G2SPaf2eX933zjfgN19Uncf0t2H7HzrXTdzOgAAAAAsBc+s2zr8KD8bAu8wtX3D1PaNSXac47sbM/yuu/v6qvpYkmOSPCbJIZs5ds/x+XFJ9khy3+7+YVVdMVXTdZsZb656b5Hk29190Dz7bG5MAAAAAFaYGYtbhyuSHJwkVXVwkr0WOd5bkrw2yTndfdVm+h5TVTtU1e2SHJnknCS7JvnGECo+JMldN7H/D4fZkfPq7u8kubyqfjv5yYtf7r3AcwEAAABgBgSLW4cPJLntsEz4D5N8YTGDdfe6JN9J8rYFdD87yT8lOSvJS7r760lOSXJIVZ2byezFSzex/0lJNlTVKZs5zuOSPLmqLkhycSYzKgEAAABYpap745WubOuGF7B8Ksk9uvvHm+h3YpJru/tVK1Taot3lP+3dz33cX866DACAbcIzXv0bsy4BAFgFqmpdd//c4/TMWLyZqaonJPlckudvKlQEAAAAgE3x8pabme4+OcnJ021V9cQkz96o65nd/fQVKwwAAACArYpgkXT327Kw5y0CAAAAQJIFLIWuqmdX1W2GN/X+XVWdV1VHr0RxAAAAAMDqtJBnLD6pu7+T5OgkeyR5YpK/WNaqAAAAAIBVbSHBYg0/H57kbd19wVQbAAAAAHAztJBgcV1VnZ5JsHhaVe2SxNuEAQAAAOBmbCEvb3lykoOSfLm7r6+q22WyHBoAAAAAuJlayIzFTrJfkmcNn3dKssOyVQQAAAAArHoLCRbfmOTwJI8dPn83yRuWrSIAAAAAYNVbyFLo+3X3wVV1fpJ099VVdctlrgsAAAAAWMUWMmPxh1W1XSZLolNVe8TLWwAAAADgZm0hweJrk3woye2r6qVJ/iXJy5a1KgAAAABgVdvkUuiqukWSy5M8N8mvJqkkv9ndl6xAbQAAAADAKrXJYLG7f1xVr+7uw5NcukI1AQAAAACr3EKWQp9eVY+uqlr2agAAAACArUJ196Y7VH03yU5JfpTk+5ksh+7uvs3ylwfjHHLIIX3uuefOugwAAACAbUZVrevuQzZu3+RS6CTp7l2WpyQAAAAAYGu12WCxqo6Yq727z1j6cgAAAACArcFmg8UkfzK1vUOSw5KsS/Iry1IRAAAAALDqLWQp9G9Mf66qOyd5xbJVBAAAAACsegt5K/TGvprkgKUuBAAAAADYeizkGYuvS3LTq6NvkeSgJBcsY00AAAAAwCq3kGcsnju1/aMk7+7uM5epHgAAAABgK7CQYHG37v7r6YaqevbGbQAAAADAzcdCnrH4e3O0Hb/EdQAAAAAAW5F5ZyxW1WOT/E6Svarq1KmvdknyH8tdGGyJKy//Ul76+GNnXQYAwGY9/11/P+sSAAAWZVNLoT+T5Mokuyd59VT7d5NsWM6iAAAAAIDVbd5gsbu/kuQrSQ5fuXIAAAAAgK3BZp+xWFX3r6pzquraqvpBVd1YVd9ZieIAAAAAgNVpIS9veX2Sxyb5YpIdk/x+ktctZ1EAAAAAwOq2qWcs/kR3/2tVbdfdNyZ5W1V9ZpnrAgAAAABWsYUEi9dX1S2TrK+qV2TyQpedlrcsAAAAAGA1W8hS6N8d+j0jyXVJ7pzk0ctZFAAAAACwum12xmJ3f6WqdkyyZ3e/aAVqAgAAAABWuYW8Ffo3kqxP8tHh80FVdeoy1wUAAAAArGILWQp9YpLDknw7Sbp7fZK1y1UQAAAAALD6LSRY/FF3X7PslQAAAAAAW42FvBX6oqr6nSTbVdXeSZ6V5DPLWxYAAAAAsJrNO2Oxqt45bH4pyf5Jbkjy7iTfSfJHy14ZAAAAALBqbWrG4n2r6q5JjkvykCSvnvru1km+v5yFAQAAAACr16aCxTdl8ibouyU5d6q9kvTQDgAAAADcDM27FLq7X9vd90zy1u6+29SfvbpbqAgAAAAAN2ObfSt0d//hShQCAAAAAGw9NhssAgAAAABsTLDInKrqWVV1SVWdMutaAAAAAFh9NvXyFm7enpbkYd19+awLAQAAAGD1MWORn1NVb8rkrd+nVtU1VfWcqe8uqqq1w59LqurNVXVxVZ1eVTsOfT5VVS+vqrOr6gtV9ctD+/+pqoOmxjqzqg6cp4bbVtWHq2pDVZ01Xz8AAAAAZkOwyM/p7qcm+XqShyR5zSa67p3kDd29f5JvJ3n01HdruvuwJH+U5M+GtrckOT5JqmqfJLfq7g3zjP2iJOd394FJnpfk5PmKqKoTqurcqjr3uu/fsOmTAwAAAGBJCBZZjMu7e/2wvS7J2qnvPjhH+/uT/HpVbZ/kSUnevomxH5TknUnS3Z9Icruq2nWujt19Uncf0t2H7LTDrcafBQAAAACjecYim/Oj/GwAvcPU9vT0wBuT7DjHdzdm+Oesu6+vqo8lOSbJY5Icsonj1hxtvcCaAQAAAFhmZiyyOVckOThJqurgJHstcry3JHltknO6+6pN9DsjyeOG4x6Z5Fvd/Z1FHhsAAACAJWLGIpvzgSRPqKr1Sc5J8oXFDNbd66rqO0netpmuJyZ5W1VtSHJ9kt9bzHEBAAAAWFqCRebU3WunPh49T7cDpvq/amr7yKntb2Xq2YtVdcdMZsqevpnjX5XJkmkAAAAAViFLoVkxVfWEJJ9L8vzu/vGs6wEAAABgy5mxyIrp7pOTnDzdVlVPTPLsjbqe2d1PX7HCAAAAABhNsMhMdffbsvnnLQIAAACwylgKDQAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGhrZl0ALKU997p7nv+uv591GQAAAADbPDMWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGhrZl0ALKXvX/ndXPLST8y6DACAed3z+b8y6xIAAJaEGYsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCxRVQVc+b2t6tqp62hGMfWVUPmPr81Kp6wlKNv1hVtbaqfmfWdQAAAACwtASLK+N5U9u7JZkzWKyq7bZg7COT/CRY7O43dffJWzDOkquqNUnWJlmyYHELrxEAAAAAS2zNrAvY1lTVh5PcOckOSf46yd2S7FhV65NcnGS7JHcfPn8syT8l+bMkVyY5KMl+G4/R3ScNYz80ycuGMb6V5MlJnprkxqp6fJJnJvnVJNcO476juw8b9l2b5NTuPrCq7pvkL5PsPIxzfHdfOc/5fCrJ+iSHJblNkid199lVdViSv0qyY5LvJXlid19WVccnecRQ+05Jbp3knsP5viPJ1UkeObTfPcmHuvu5w7GOTvKiJLdK8qVhzGur6ookb01ydJLXJ3nP5n8TAAAAACwnweLSe1J3X1VVOyY5J8mDkzyjuw9KfhLwHTD1+chMQrsDuvvyucaoqg9kMrv0zUmO6O7Lq+q2Q583Jbm2u181jPerSdLdl1TVLavqbt395STHJXlfVW2f5HVJjunub1bVcUlemuRJmzinnbr7AVV1RCYB3wFJLh1q+VFVHZVJ4Pnoof/hSQ4c6jsyyXO6+9eH+o7PJEC9T5IbklxWVa/LJJz870mO6u7rqur/TfJfkrx4GPP73f2gBf0GAAAAAFh2gsWl96yqetSwfeckey9gn7OnQsX5xtgjyRk39evuqxYw7vuSPCbJX2QSLB6XZN9MgsGPVVUymf0452zFKe8ejnlGVd2mqnZLskuSd1TV3kk6yfZT/T+2mfo+3t3XJElVfT7JXTNZIr5fkjOHum6Z5LNT+7x3vsGq6oQkJyTJnrvefjOnAgAAAMBSECwuoWF23lFJDu/u64dlxDssYNfrFjBGZRLgjfHeJO+vqg8m6e7+YlXdK8nF3X34iHE2Pm4neUmST3b3o4ZZmJ+a+v66bNoNU9s3ZvLPYWUSSD52nn3mHXNYKn5Skhxwp33HXiMAAAAAtoCXtyytXZNcPQSC90hy/6H9h8MS5CT5biaz/caO8dkkD66qvZKkqm67ufG6+0uZBHcvyE9n/F2WZI+qOnwYZ/uq2n8z53Xc0PdBSa4ZZhvumuRrw/fHb2LfzZ3vTc5K8sCq+qXhWLeuqn0WsB8AAAAAMyBYXFofTbKmqjZkMqPvrKH9pCQbquqU7v6PTJb7XlRVr1zoGN39zUyW+36wqi7IT4PCjyR5VFWtr6pfnmO89yZ5fCbLotPdP0hybJKXD+Osz9RbpedxdVV9JsmbMnlhTJK8IsmfV9WZmSynns+GJD+qqguq6o/n6zSc3/FJ3j2c+1lJ7rGZugAAAACYkeq2cpT5DUuxn9Pd5866loU44E779vuf9jezLgMAYF73fP6vzLoEAIBRqmpddx+ycbsZiwAAAADAaF7eQpKkqt6Q5IEbNf91dx85g3IAAAAAWOUEiyRJuvvps64BAAAAgK2HpdAAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMtmbWBcBS2mHPXXLP5//KrMsAAAAA2OaZsQgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGWzPrAmApff3rX8+JJ5446zIAYMX5+w8AgJVmxiIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbC4xKrqiqrafQWO86mqOmQT3/+vqtptM2McX1V3XPLifvYYR1bVA5bzGAAAAACsPMHiKlJVa5ZqrO5+eHd/ezPdjk8yKljcghqPTCJYBAAAANjGCBYXoap2qqp/qqoLquqiqjpu+OqZVXVeVV1YVfcY+h5WVZ+pqvOHn/sO7cdX1fur6iNJTh/GfGtVnTP0PWbot2NVvaeqNlTVe5PsuJnarqiq3atqbVVdUlVvrqqLq+r0YaxjkxyS5JSqWj+03beqPl1V66rqtKracxjrU1X1sqr6dJJnb6Lfs6rq80ON76mqtUmemuSPh2P8clX99nCtLqiqMzZR/w5V9bbhGp5fVQ9ZxK8KAAAAgCW2ZDPkbqYemuTr3f2IJKmqXZO8PMm3uvvgqnpakuck+f0klyY5ort/VFVHJXlZkkcP4xye5MDuvqqqXpbkE939pGEp89lV9c9JnpLk+u4+sKoOTHLeiDr3TvLY7v6Dqnpfkkd397uq6hlJntPd51bV9klel+SY7v7mEJK+NMmThjF26+4HD/0+PU+/P02yV3ffUFW7dfe3q+pNSa7t7lcN1+jCJL/W3V/bzFLtpydJd99rCGdPr6p9uvv7G3esqhOSnJAku+6664jLAgAAAMCWEiwuzoVJXlVVL0/yj939f6oqST44fL8uyW8N27smeUdV7Z2kk2w/Nc7HuvuqYfvoJI+squcMn3dIcpckRyR5bZJ094aq2jCizsu7e/1UTWvn6LNvkgOSfGw4h+2SXDn1/XsX0G9DJjMgP5zkw/PUcmaStw8B5wfn6ZMkD8ok6Ex3X1pVX0myz3CMn9HdJyU5KUnueMc79ibGBAAAAGCJCBYXobu/UFX3TfLwJH9eVacPX90w/LwxP73GL0nyye5+1LBE+FNTQ103tV2ZzCi8bPpYQ4i3paHZDVPbN2buZdSV5OLuPnyeMa5bQL9HZBKAPjLJC6pq/407dPdTq+p+Q9/1VXVQd//HPPUAAAAAsEp5xuIiDG9Uvr6735XkVUkO3kT3XZN8bdg+fhP9TsvkGY01HOM+Q/sZSR43tB2Q5MAtr/wnvptkl2H7siR7VNXhwzG2nysYnK9fVd0iyZ27+5NJnptktyQ7b3SMVNXdu/tz3f3CJN9Kcud5aps+330ymbV52Tx9AQAAAFhhgsXFuVcmz0Bcn+T5Sf7HJvq+IpNZjWdmsnx4Pi/JZJn0hqq6aPicJH+TZOdhCfRzk5y9yNqT5O1J3jTUv12SY5O8vKouSLI+c7zNubt/ME+/7ZK8a3iG4vlJXjO8lfojSR5108tbkrxyeCHLRZmEhxfMU9sbk2w3jPfeJMd39w3z9AUAAABghVW3R9Kx7bjjHe/YJ5xwwqzLAIAVd+KJJ866BAAAtlFVta67D9m43YxFAAAAAGA0L2/ZylXV55LcaqPm3+3uC2dRz1hV9WtJXr5R8+Xd/ahZ1AMAAADAwggWt3Ldfb9Z17AY3X1aJi+sAQAAAGArYik0AAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAowkWAQAAAIDRBIsAAAAAwGiCRQAAAABgNMEiAAAAADCaYBEAAAAAGE2wCAAAAACMJlgEAAAAAEYTLAIAAAAAo1V3z7oGWDKHHHJIn3vuubMuAwAAAGCbUVXruvuQjdvNWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjrZl1AbCUrr76krzv/YfNugwAWDGP+e2zZ10CAAA3U2YsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMssupV1UFV9fBZ1wEAAADATwkW2RoclESwCAAAALCKCBZZEVW1tqouraq3VNVFVXVKVR1VVWdW1Rer6rCq2qmq3lpV51TV+VV1TFXdMsmLkxxXVeur6rhZnwsAAAAAyZpZF8DNyi8l+e0kJyQ5J8nvJHlQkkcmeV6Szyf5RHc/qap2S3J2kn9O8sIkh3T3M2ZRNAAAAAA/T7DISrq8uy9Mkqq6OMnHu7ur6sIka5P8YpJHVtVzhv47JLnL5gatqhMyCSuz++63XI66AQAAANiIYJGVdMPU9o+nPv84k38Wb0zy6O6+bHqnqrrfpgbt7pOSnJQkd7/7Tr1k1QIAAAAwL89YZDU5Lckzq6qSpKruM7R/N8kuM6sKAAAAgJ8jWGQ1eUmS7ZNsqKqLhs9J8skk+3l5CwAAAMDqYSk0K6K7r0hywNTn4+f57ilz7HtVkkOXtUAAAAAARjFjEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYbc2sC4Cl9Au/cM885rfPnnUZAAAAANs8MxYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaGtmXQAspc9f/Z3c++9Pm3UZALBsLjj212ZdAgAAJDFjEQAAAADYAoJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGA0wSIAAAAAMJpgEQAAAAAYTbAIAAAAAIwmWAQAAAAARhMsAgAAAACjCRYBAAAAgNEEiwAAAADAaIJFAAAAAGC0m1WwWFVrq+p7VbW+qi6oqs9U1b7Dd0dW1T9u4bhXVNXu83z3t1X1wGF7TVV9q6r+fKM+r6yqi6vqlXPs/8iq+tMtqWsBdV9QVe9ejrGnjvGWqtpvOY8BAAAAwMpbkWCxJlZLiPml7j6ou++d5B1JnrfMx7tfkrOG7aOTXJbkMVVVU32ekuTg7v6T6R2rak13n9rdf7HURVXVPTP5/R9RVTst9fjDMbbr7t/v7s8vx/gAAAAAzM6yhX3D7MBLquqNSc5L8ndVde4wM+9FU/0OHWYOXlBVZ1fVLlW13TCL75yq2lBVT9nEcWroe1FVXVhVx40o8zZJrp5jzMOGms7faFbjdlX1quE4G6rqmRvtt2NVfbSq/mD4fM8kX+juG4cuj03y10n+Lcn9hz6nJtkpyeeq6riqentV/WVVfTLJy6vq+Kp6/dD3DlX1oeFaXVBVDxjaP1xV64Zre8JUPddW1UuHvmdV1R2myv2dJO9McnqSR07t86mqek1VnTH8/g6tqg9W1Rer6n9M9Xv88PtaP8zK3G7qmC+uqs8lOXwY75Dhu4dW1XlDPR/fzLU+fjjuR4djv2LE7xUAAACAZbZmmcffN8kTu/tpVXXb7r5qCKA+XlUHJrk0yXuTHNfd51TVbZJ8L8mTk1zT3YdW1a2SnFlVp3f35XMc47eSHJTk3kl2T3JOVZ3R3VfOU9Pdq2p9kl2S3DqTGYUbuzTJEd39o6o6KsnLkjw6yQlJ9kpyn+G7207ts3OS9yQ5ubtPHtoeluSjySR0TPKrmcxO3C2TkPGz3f3Iqrq2uw8a+j0syT5JjuruG6vq+KljvDbJp7v7UcN13Hlof9JwbXcczv8D3f0fmQSWZ3X384dg7g+S3BQOHpfk/8nkd/SMJNNLon/Q3UdU1bOT/EOS+ya5KsmXquo1SW4/7P/A7v7hEB4/LsnJwzEv6u4XDueT4eceSd48XNfLp67dfNc6mfxe75PkhiSXVdXruvvfN/5lDWHqCUmy/e633/hrAAAAAJbBcgeLX+num5YBP2YIgNYk2TPJfkk6yZXdfU6SdPd3kqSqjk5yYFUdO+y7a5K9k8wVLD4oybuHWYH/X1V9OsmhSU6dp6YvTYV4xyU5KclDN+qza5J3VNXeQ43bD+1HJXlTd/9oqPeqqX3+IckruvuUqbZfS/LEYfvXk3yyu6+vqg8keUFV/fHUbMZp75+n/VeSPGE49o1Jrhnan1VVjxq275zJtfqPJD9IctNzI9dlEiSmqg5N8s3u/kpVfTXJW6vqF7r7ptmbN127C5NcfFNIW1VfHsZ/UCZh4zlDcLhjkm8M+9yY5ANz1H7/JGfcFA5PXbv5rnWSfLy7rxmO/fkkd03yc8Fid5+Uye8xt777Pj3HsQEAAABYYssdLF6XJFW1V5LnJDm0u6+uqrcn2SFJZRImbaySPLO7T1vAMWrzXeZ1apK3zdH+kkxCwEdV1dokn5o61nzB1ZlJHlZV/7O7u6punWS37v768P1jkzywqq4YPt8uyUOS/PMcY1230BOoqiMzCTwPH0LLT2VybZPkh919U7035qe/78cmucdULbfJZJbgW4bPNww/fzy1fdPnNZlch3d093+bo6TvzxOKznft5rvW03VsXD8AAAAAM7ZSL1S5TSZh2TXDc/4eNrRfmuSOwwy61OT5imuSnJbkD6tq+6F9n5r/BSNnJDmuJs8/3CPJEUnOXmBdD0rypTnad03ytWH7+Kn205M8dagxGy2FfmEmswTfOHx+SJJPDv1uMxzrLt29trvXJnl6JgHfGB9P8ofDmNsN4+6a5OohVLxHhmc3zqcmL9H57SQHTtVyzMhaPp7k2Kq6/TDmbavqrpvZ57NJHjyEzNPXbr5rDQAAAMAqtiLBYndfkOT8JBcneWsms/vS3T/I5Fl9r6uqC5J8LJPZdm9J8vkk51XVRUn+NvPPVvtQkg1JLkjyiSTP7e7/u4ly7j68cOSCTJ7n9/tz9HlFkj+vqjOTbDfV/pZMXryyYdj/dzba74+S7DA8z/Anz1fM5DmQn+ju6Rl4/5DkkcMzJBfq2UkeUlUXZrK0ef/hGGuqakMms//O2sT+ySR4/Vp3f22q7Ywk+1XVngspYnjL839Pcvpw3I9lsrx9U/t8M5PnIH5wuHbvHb6a71oDAAAAsIrVT1fKspSq6rwk9+vuH866lpuTW999n9775a+bdRkAsGwuOPbXZl0CAAA3M1W1rrsP2bjdM+uWSXcfPOsaAAAAAGC5bDXBYlXdK8k7N2q+obvvt5i+AAAAAMB4W02w2N0XJjloqfsCAAAAAOOt1FuhAQAAAIBtiGARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGWzPrAmAp7fcLt8m5x/7arMsAAAAA2OaZsQgAAAAAjCZYBAAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBo1d2zrgGWTFV9N8lls64DVrHdk3xr1kXAKuYegU1zj8CmuUdg09wjW6+7dvceGzeumUUlsIwu6+5DZl0ErFZVda57BObnHoFNc4/AprlHYNPcI9seS6EBAAAAgNEEiwAAAADAaIJFtjUnzboAWOXcI7Bp7hHYNPcIbJp7BDbNPbKN8fIWAAAAAGA0MxYBAAAAgNEEi2wVquqhVXVZVf1rVf3pHN9XVb12+H5DVR280H1hW7DIe+StVfWNqrpoZauGlbOl90hV3bmqPllVl1TVxVX17JWvHpbfIu6RHarq7Kq6YLhHXrTy1cPyW8y/aw3fb1dV51fVP65c1bCyFvnfJFdU1YVVtb6qzl3ZylkMwSKrXlVtl+QNSR6WZL8kj62q/Tbq9rAkew9/TkjyNyP2ha3aYu6RwduTPHT5K4XZWOQ98qMk/7W775nk/kme7u8RtjWLvEduSPIr3X3vJAcleWhV3X8l6oaVsgT/rpUkz05yyTKXCjOzRPfJQ7r7oO4+ZLnrZekIFtkaHJbkX7v7y939gyTvSXLMRn2OSXJyT5yVZLeq2nOB+8LWbjH3SLr7jCRXrWjFsLK2+B7p7iu7+7wk6e7vZvIfhXdayeJhBSzmHunuvnbos/3wx0Pc2dYs6t+1quoXkzwiyVtWsmhYYYu6T9h6CRbZGtwpyb9Pff5qfv4/6ubrs5B9YWu3mHsEbg6W5B6pqrVJ7pPkc0tfIszUou6RYYnn+iTfSPKx7naPsK1Z7N8jf5XkuUl+vEz1wWqw2Pukk5xeVeuq6oRlq5IlJ1hka1BztG38f8Ln67OQfWFrt5h7BG4OFn2PVNXOST6Q5I+6+ztLWBusBou6R7r7xu4+KMkvJjmsqg5Y2vJg5rb4HqmqX0/yje5et/Rlwaqy2H/femB3H5zJcumnV9URS1kcy0ewyNbgq0nuPPX5F5N8fYF9FrIvbO0Wc4/AzcGi7pGq2j6TUPGU7v7gMtYJs7Ikf49097eTfCqe28u2ZzH3yAOTPLKqrshkaeivVNW7lq9UmJlF/V3S3Tf9/EaSD2WytJqtgGCRrcE5Sfauqr2q6pZJ/nOSUzfqc2qSJwxvmbp/kmu6+8oF7gtbu8XcI3BzsMX3SFVVkr9Lckl3/+XKlg0rZjH3yB5VtVuSVNWOSY5KcukK1g4rYYvvke7+b939i929dtjvE939+BWtHlbGYv4u2amqdkmSqtopydFJLlrJ4tlya2ZdAGxOd/+oqp6R5LQk2yV5a3dfXFVPHb5/U5L/leThSf41yfVJnripfWdwGrBsFnOPJElVvTvJkUl2r6qvJvmz7v67lT0LWD6LvEcemOR3k1w4PEMuSZ7X3f9rBU8BltUi75E9k7xjeBvoLZK8r7v/caXPAZbTYv9dC24OFnmf3CHJhyb/PzdrkvzP7v7oCp8CW6i6PWILAAAAABjHUmgAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjCZYBAAAAABGEywCAMAKqKprZ10DAMBSEiwCAAAAAKMJFgEAYAtU1cur6mlTn0+sqj+rqo9X1XlVdWFVHTPHfkdW1T9OfX59VR0/bN+3qj5dVeuq6rSq2nNof1ZVfb6qNlTVe1bg9AAANmvNrAsAAICt1HuS/FWSNw6fH5PkoUle093fqardk5xVVad2d29usKraPsnrkhzT3d+squOSvDTJk5L8aZK9uvuGqtpt6U8FAGA8wSIAAGyB7j6/qm5fVXdMskeSq5NcmeQ1VXVEkh8nuVOSOyT5vwsYct8kByT5WFUlyXbDeEmyIckpVfXhJB9ewtMAANhigkUAANhyf5/k2CT/KZMZjI/LJGS8b3f/sKquSLLDRvv8KD/7SKKbvq8kF3f34XMc5xFJjkjyyCQvqKr9u/tHS3YWAABbwDMWAQBgy70nyX/OJFz8+yS7JvnGECo+JMld59jnK0n2q6pbVdWuSX51aL8syR5VdXgyWRpdVftX1S2S3Lm7P5nkuUl2S7Lzcp4UAMBCmLEIAABbqLsvrqpdknytu6+sqlOSfKSqzk2yPsmlc+zz71X1vkyWN38xyflD+w+q6tgkrx0CxzWZPMPxC0neNbRVJs9w/PaynxwAwGbUAp4jDQAAAADwMyyFBgAAAABGEywCAAAAAKMJFgEAAACA0QSLAAAAAMBogkUAAAAAYDTBIgAAAAAwmmARAAAAABhNsAgAAAAAjPb/AzBFxHWjGto8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='values', y='features', data=feature_imp.sort_values(by='values', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 이해하기 : XGBoost\n",
    "\n",
    "* 트리모델 진화 과정: 결정 트리 -> 배깅 -> 랜덤 포레스트 -> 부스팅 -> 경사 부스팅 -> XG 부스팅\n",
    "* 배깅  \n",
    "  배깅은 부트스트랩(복원추출 허용) 훈련셋을 사용하는 트리 모델. 부트스트랩은 데이터의 일부분을 무작위로 추출하는 방법. 이런식으로 추출한 데이터의 여러 부분집합을 사용해 여러 트리를 만들어 오버피팅을 방지.\n",
    "* 부스팅과 에이다부스트  \n",
    "  부스팅은 랜덤 포레스트에서 한 단계 더 발전한 방법으로 역시 여러 트리를 만드는 모델. 가장 큰 차이점은 랜덤 포레스트에서 각 트리는 독립적이나 부스팅에서는 그렇지 않다. 부스팅은 이전 트리의 정보를 활용해 이전 트리와의 시너지를 극대화 하려고 노력한다. 부스팅의 대표적인 알고리즘은 에이다부스트이다. 단계적으로 트리를 만들고 이전 단계에서의 분류 결과에 따라 각 데이터에 가중치를 부여/수정 한다.\n",
    " * 경사 부스팅과 XGBoost  \n",
    "   경사 부스팅의 경우는 경사하강법을 이용한다. 이전 모델의 에러를 기반으로 다음 트리를 만들어간다. XGBoosting의 경우 가중치 분위수 스케치, 희소성 인식 하이퍼파라미터 기능을 추가했다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1acd79579433d099a774017ba86d1314ddef5b0bdc137c47399c89169a3fec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
