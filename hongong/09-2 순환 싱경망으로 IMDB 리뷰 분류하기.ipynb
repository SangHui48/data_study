{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순환 싱경망으로 IMDB 리뷰 분류하기\n",
    "#### 핵심 키워드: 말뭉치, 토큰, 원-핫 인코딩, 단어 임배딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lengths = np.array([len(x) for x in train_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.00925 178.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lengths), np.median(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = pad_sequences(train_input, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
      "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
      "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
      "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
      "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
      "   6   2  46   7  14  20  10  10 470 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
      "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
      "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
      "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
      "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
      "   2   2 290   2  46  48  64  18   4   2]\n"
     ]
    }
   ],
   "source": [
    "print(train_seq[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq = pad_sequences(val_input, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.SimpleRNN(8, input_shape=(100, 500)))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh = keras.utils.to_categorical(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100, 500)\n"
     ]
    }
   ],
   "source": [
    "print(train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_oh[0][0][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(train_oh[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_oh = keras.utils.to_categorical(val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 8)                 4072      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081\n",
      "Trainable params: 4,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanghui\\Desktop\\toyproject\\data_study_20220628\\hongong\\09-2 순환 싱경망으로 IMDB 리뷰 분류하기.ipynb 셀 25\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanghui/Desktop/toyproject/data_study_20220628/hongong/09-2%20%EC%88%9C%ED%99%98%20%EC%8B%B1%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m checkpoint_cb \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mbest-simplernn-model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanghui/Desktop/toyproject/data_study_20220628/hongong/09-2%20%EC%88%9C%ED%99%98%20%EC%8B%B1%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m early_stopping_cb \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanghui/Desktop/toyproject/data_study_20220628/hongong/09-2%20%EC%88%9C%ED%99%98%20%EC%8B%B1%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C%20IMDB%20%EB%A6%AC%EB%B7%B0%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_oh, train_target, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(val_oh, val_target), callbacks\u001b[39m=\u001b[39;49m[checkpoint_cb, early_stopping_cb])\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2449\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2630\u001b[0m         args,\n\u001b[0;32m   2631\u001b[0m         kwargs,\n\u001b[0;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1117\u001b[0m       original_func,\n\u001b[0;32m   1118\u001b[0m       args,\n\u001b[0;32m   1119\u001b[0m       kwargs,\n\u001b[0;32m   1120\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1121\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1122\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1123\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1124\u001b[0m       ))\n\u001b[0;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileswdaig47.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\engine\\training.py:893\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    892\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:537\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m   \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[39m  This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    538\u001b[0m       loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    539\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:590\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    588\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m   grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(tape, loss, var_list, grad_loss)\n\u001b[0;32m    592\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes([\n\u001b[0;32m    593\u001b[0m     v \u001b[39mfor\u001b[39;00m g, v \u001b[39min\u001b[39;00m grads_and_vars\n\u001b[0;32m    594\u001b[0m     \u001b[39mif\u001b[39;00m g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m v\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m tf\u001b[39m.\u001b[39mresource\n\u001b[0;32m    595\u001b[0m ])\n\u001b[0;32m    597\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:471\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    470\u001b[0m   \u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m   grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    472\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:444\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    438\u001b[0m cond_grad_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    439\u001b[0m     grad_cond_name, grad_cond, loop_vars, {},\n\u001b[0;32m    440\u001b[0m     func_graph\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mWhileCondFuncGraph(grad_cond_name))\n\u001b[0;32m    442\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[39mlen\u001b[39m(loop_vars))\n\u001b[1;32m--> 444\u001b[0m outputs \u001b[39m=\u001b[39m _build_while_op(\n\u001b[0;32m    445\u001b[0m     loop_vars,\n\u001b[0;32m    446\u001b[0m     cond_grad_graph,\n\u001b[0;32m    447\u001b[0m     body_grad_graph,\n\u001b[0;32m    448\u001b[0m     output_shapes\u001b[39m=\u001b[39;49m[t\u001b[39m.\u001b[39;49mshape \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m body_grad_graph\u001b[39m.\u001b[39;49moutputs],\n\u001b[0;32m    449\u001b[0m     parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[0;32m    450\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m_grad\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m while_op\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    451\u001b[0m     num_original_outputs\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(body_grad_graph\u001b[39m.\u001b[39;49moutputs),\n\u001b[0;32m    452\u001b[0m     stateful_parallelism\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[0;32m    454\u001b[0m \u001b[39m# See comment in while_loop.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m outputs \u001b[39m=\u001b[39m [array_ops\u001b[39m.\u001b[39midentity(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:499\u001b[0m, in \u001b[0;36m_build_while_op\u001b[1;34m(loop_vars, cond_graph, body_graph, output_shapes, parallel_iterations, name, num_original_outputs, stateful_parallelism)\u001b[0m\n\u001b[0;32m    497\u001b[0m   while_op\u001b[39m.\u001b[39m_body_graph \u001b[39m=\u001b[39m body_graph\n\u001b[0;32m    498\u001b[0m   \u001b[39mreturn\u001b[39;00m tensors\n\u001b[1;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mrun_as_function_for_tape_gradients(_make_op, loop_vars)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_util_v2.py:376\u001b[0m, in \u001b[0;36mrun_as_function_for_tape_gradients\u001b[1;34m(make_op, inputs)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m   \u001b[39mreturn\u001b[39;00m make_op(inputs)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:477\u001b[0m, in \u001b[0;36m_build_while_op.<locals>._make_op\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_op\u001b[39m(inputs):\n\u001b[0;32m    475\u001b[0m   while_op, tensors \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mget_op_and_outputs(op_fn(\n\u001b[0;32m    476\u001b[0m       inputs,\n\u001b[1;32m--> 477\u001b[0m       util\u001b[39m.\u001b[39;49mcreate_new_tf_function(cond_graph),\n\u001b[0;32m    478\u001b[0m       util\u001b[39m.\u001b[39mcreate_new_tf_function(body_graph),\n\u001b[0;32m    479\u001b[0m       output_shapes\u001b[39m=\u001b[39moutput_shapes,\n\u001b[0;32m    480\u001b[0m       parallel_iterations\u001b[39m=\u001b[39mparallel_iterations,\n\u001b[0;32m    481\u001b[0m       name\u001b[39m=\u001b[39mname))\n\u001b[0;32m    482\u001b[0m   _copy_handle_data(body_graph\u001b[39m.\u001b[39moutputs, tensors)\n\u001b[0;32m    483\u001b[0m   util\u001b[39m.\u001b[39mmaybe_set_lowering_attr(while_op)\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_util_v2.py:71\u001b[0m, in \u001b[0;36mcreate_new_tf_function\u001b[1;34m(func_graph)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m\"\"\"Converts func_graph to a TF_Function and adds it to the current graph.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m  The name of the new TF_Function.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m func \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39m_EagerDefinedFunction(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     func_graph\u001b[39m.\u001b[39mname, func_graph, func_graph\u001b[39m.\u001b[39minputs, func_graph\u001b[39m.\u001b[39moutputs, {})\n\u001b[1;32m---> 71\u001b[0m func\u001b[39m.\u001b[39;49madd_to_graph(func_graph\u001b[39m.\u001b[39;49mouter_graph)\n\u001b[0;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m func_graph\u001b[39m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:446\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.add_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m g\u001b[39m.\u001b[39m_is_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname):\n\u001b[1;32m--> 446\u001b[0m     g\u001b[39m.\u001b[39;49m_add_function(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    447\u001b[0m   \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_functions\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m g\u001b[39m.\u001b[39m_is_function(f\u001b[39m.\u001b[39mname):\n",
      "File \u001b[1;32mc:\\Users\\sanghui\\miniconda3\\envs\\hongong\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3621\u001b[0m, in \u001b[0;36mGraph._add_function\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m   3619\u001b[0m       pywrap_tf_session\u001b[39m.\u001b[39mTF_GraphCopyFunction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph, func, gradient)\n\u001b[0;32m   3620\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphCopyFunction(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_graph, func, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   3622\u001b[0m \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_functions[compat\u001b[39m.\u001b[39mas_str(name)] \u001b[39m=\u001b[39m function\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
    "model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "history = model.fit(train_oh, train_target, epochs=100, batch_size=64, validation_data=(val_oh, val_target), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hongong')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47060db7b4131a050c116dcb884f3b6d5803ef221a5d5ec6d93aa64695a9c85b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
